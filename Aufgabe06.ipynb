{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group XX (Name 1, Name 2, Name 3, Name 4)\n",
    "\n",
    "# Homework 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This homework revolves all around eigenvalues, eigenvectors, and corresponding matrix decompositions.\n",
    "Let's start with intialization as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                # basic arrays, vectors, matrices\n",
    "import scipy as sp                # matrix linear algebra \n",
    "\n",
    "import matplotlib                 # plotting\n",
    "import matplotlib.pyplot as plt   # plotting\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"<style>.output_png { display: table-cell; text-align: center; vertical-align: middle; }</style>\"\"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Power Iteration to Compute the Largest Eigenpair\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the course, we discussed briefly several methods to compute eigenvalues of a matrix $A$. Among these, the *Power Iteration* is the simplest. However, it is a good illustration of the general idea behind eigenvalue algorithms. It calculates the largest eigenvalue and the corresponding eigenvector in an iterative manner by repeated application of $A$ to a vector $\\mathbf{b}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Task**: Complete the function `power_iteration` below to implement the power iteration algorithm to compute the largest eigenpair, given the square matrix `A`. The function should have the following properties:\n",
    "\n",
    "- It should return the sequence of $\\mu_k$ and $\\mathbf{b}$, where $\\mu_k$ is the Rayleigh coefficient obtained in the $k$-th iteration (This is used for visual verification in the code below the function by plotting the $\\mu_k$). The other output $\\mathbf{b}$ is the approximation of the eigenvector.\n",
    "- `power_iteration` should terminate if either the maximum number of iterations (`maxiter`) is reached, or if $(\\mu_k,b_k)$ is (numerically) an eigenpair, i.e. $Ab_k$ and $\\mu_k b_k$ are close. You may use [`numpy.allclose`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.allclose.html) to check this.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_iteration(A, maxiter = 50):\n",
    "    \"\"\"perform power iteration on A and return the sequence of Rayleigh coefficients\"\"\"\n",
    "    # TODO \n",
    "    n = len(A)\n",
    "    b = np.random.rand(n)\n",
    "    mu = np.zeros(1)\n",
    "\n",
    "    for i in range(maxiter):        \n",
    "        \n",
    "        #Algorithmus\n",
    "        Mul = np.matmul(A, b)\n",
    "        mu_i = (b.T@Mul)/(b.T@b)\n",
    "        \n",
    "        #mu in Vektor hinzufügeh\n",
    "        mu = np.append(mu, mu_i)\n",
    "        \n",
    "        b = Mul/sum(np.sqrt(Mul**2))\n",
    "        \n",
    "        #Break wenn close    \n",
    "        x = np.allclose(Mul, mu[i]*b) \n",
    "        \n",
    "        if x == True:\n",
    "            break\n",
    "\n",
    "        \n",
    "    return mu,b\n",
    "\n",
    "# test power iteration (largest eigenvalue of A = 18)\n",
    "A = np.array([[9, 0, 3], [4, 6, 12], [15, 9, 3]])\n",
    "\n",
    "mu, b = power_iteration(A)\n",
    "\n",
    "print( \"largest eigenvalue =\", mu[len(mu)-1], \"(%d iterations)\"%len(mu) )\n",
    "print( \"corresponding eigenvector = \",b)\n",
    "# visualize the convergence of the Rayleigh coefficients\n",
    "\n",
    "fig = plt.plot( mu,linewidth=4.0)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the algorithm is correct, it should return the maximum eigenvalue of $A$.\n",
    "\n",
    "Let's inspect convergence by plotting $\\Delta_k = |\\mu_{k+1} - \\mu_k|$, i.e. the order of magnitude of successive updates, in a logarithmic plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_convergence(ax, mu):\n",
    "    delta = np.abs(mu[1:]-mu[:-1])\n",
    "    ax.plot(delta)\n",
    "    ax.set_yscale('log')\n",
    "    ax.grid(True)\n",
    "    \n",
    "plot_convergence(plt.gca(), mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Task**: visualize and compare the convergence for the following three matrices:\n",
    "\n",
    "$$A_1 = \\mathrm{diag}(10,2,1), \\ A_2 = \\mathrm{diag}(10,8,1),\\ A_3 = \\mathrm{diag}(10,9.9,1).$$\n",
    "\n",
    "What is the explanation for the drastically differing convergence behavior?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "\n",
    "A1 = np.array([[10, 0, 0], [0, 2, 0], [0, 0, 1]])\n",
    "A2 = np.array([[10, 0, 0], [0, 8, 0], [0, 0, 1]])\n",
    "A3 = np.array([[10, 0, 0], [0, 9.9, 0], [0, 0, 1]])\n",
    "\n",
    "mu1, b1 = power_iteration(A1)\n",
    "mu2, b2 = power_iteration(A2)\n",
    "mu3, b3 = power_iteration(A3)\n",
    "\n",
    "plot_convergence(plt.gca(), mu1) #blau\n",
    "plot_convergence(plt.gca(), mu2) #orange\n",
    "plot_convergence(plt.gca(), mu3) #grün"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### QR Decomposition using the Householder Transformations\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the exercise 5, we have seen the QR decomposition of a matrix using the Gram-Schmidt process. In this exercise, the task is to implement it using the more stable Householder transformations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Task**: Complete the function `QR_decomposition_Householder` below to implement the QR decomposition of the given square matrix `A`. The function should simply return the $Q$ and $R$ matrices as outputs. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QR_decomposition_Householder(A):\n",
    "   \n",
    "    # TODO \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return Q,R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In below, we can check the correctness of the implementation on a test matrix using the identities $A = QR$ and $Q^\\top Q = I$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.rand(4,4)\n",
    "Q,R = QR_decomposition_Householder(A)\n",
    "Acheck = Q@R\n",
    "print(A-Acheck)\n",
    "Icheck = np.transpose(Q)@Q\n",
    "print(Icheck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Computing Eigenvalues using the QR Algorithm\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Task**: Complete the function `compute_eigenvalues`, which computes the eigenvalues of the square matrix $A$ using the QR algorithm. The function should return the vector of eigenvalues as the output. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eigenvalues(A):\n",
    "   \n",
    "    # TODO \n",
    "    A = np.random.rand(N, N)\n",
    "\n",
    "    max_iter = 1000\n",
    "    \n",
    "    Q = np.empty((N, N)) \n",
    "    u = np.empty((N, N)) \n",
    "\n",
    "    u[:, 0] = A[:, 0]\n",
    "    Q[:, 0] = u[:, 0] / np.linalg.norm(u[:, 0])\n",
    "\n",
    "    for k in range(max_iter):\n",
    "        \n",
    "        for i in range(1, N):\n",
    "\n",
    "            u[:, i] = A[:, i]\n",
    "            for j in range(i):\n",
    "                u[:, i] -= (A[:, i] @ Q[:, j]) * Q[:, j] \n",
    "\n",
    "            Q[:, i] = u[:, i] / np.linalg.norm(u[:, i]) \n",
    "\n",
    "        R = np.zeros((N, N ))\n",
    "        for i in range(N):\n",
    "            for j in range(i, N):\n",
    "                R[i, j] = A[:, j] @ Q[:, i]\n",
    "            \n",
    "        A = R @ Q \n",
    "        \n",
    "        '''\n",
    "        if k % 1000 == 0:\n",
    "            print(A)\n",
    "        '''\n",
    "    eigvals = np.diag(A, k = 0)\n",
    "    return eigvals\n",
    "\n",
    "'''\n",
    "Hi Jan, ich weiß es kommt leider nicht das richtige ergebnis raus. Ich habe rumprobiert, aber es\n",
    "konvergiert nicht egal, wie ichs versuche. Dachte eigentlich es würde so im skript stehen,\n",
    "wie ichs implementiert habe\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check the implementation on a random matrix $A$, which has real eigenvalues. We can easily generate such a matrix using the diagonalization\n",
    "\\begin{equation}\n",
    "A = S \\Lambda S^{-1}\n",
    "\\end{equation}\n",
    "We first generate a diagonal matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 6\n",
    "Lambda = np.diag(np.random.rand(N)*10)\n",
    "print(Lambda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate a square random $S$ matrix. Note that this matrix will be invertible with almost certain probability. Using $S$ and $\\Lambda$, we can generate a random matrix with real eigenvalues to test the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.random.random((N,N))\n",
    "Sinv = np.linalg.inv(S)\n",
    "A = S@Lambda@Sinv\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigenvalues of $A$ can be easily found by using the `numpy.linalg.eigvals` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvaluesOfA = np.linalg.eigvals(A)\n",
    "print(eigenvaluesOfA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to use 'compute_eigenvalues'. If the implementation is correct, it should return exactly the same values as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvaluesOfA = compute_eigenvalues(A)\n",
    "print(eigenvaluesOfA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
